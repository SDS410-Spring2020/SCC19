---
title: "Sentiment Analysis Workspace"
author: "Yejin Hwang"
date: "4/14/2020"
output: html_document
---

```{r settingUp}
library(dplyr)
library(tidytext)
library(textdata)
library(wordcloud)
library(reshape2)
library(lubridate)
```


```{r, eval=FALSE}
# afinn from Finn Ã…rup Nielsen,
# bing from Bing Liu and collaborators, and
# nrc from Saif Mohammad and Peter Turney.

# Count words by sentiment in each lexicon:
get_sentiments("nrc") %>%
  count(sentiment) 

get_sentiments("bing") %>% 
  count(sentiment)

# Access eacg lexicon and assign it:
nrc <- get_sentiments("nrc")

bing <- get_sentiments("bing")

# Use data frame with text data, and implement sentiment analysis using inner joint
our_text_from_letters %>%
  inner_join(nrc)

our_text_from_letters %>%
  inner_join(bing)
```

```{r}
# nrc
# Citation: Saif M. Mohammad and Peter Turney. (2013), ``Crowdsourcing a Word-Emotion Association Lexicon.'' Computational Intelligence, 29(3): 436-465.

get_sentiments("nrc") %>%
  count(sentiment) 

nrc <- get_sentiments("nrc")
```

```{r}
# Our data (w/ code from other workspaces)
load("textdata.Rda")

df_long <- df_full %>%
  unnest_tokens(word, content)

df_filterNRCwords <- df_long %>% 
  inner_join(nrc) 

# Comparing pre-COVID19 and post-COVID19
df_prePost <- df_filterNRCwords %>% 
  mutate(postCo = if_else(date>="2020-02-07", 1, 0)) 

df_prePost %>% 
  group_by(postCo,sentiment) %>% 
  summarise(N=n()) %>% 
  group_by(sentiment) %>% 
  arrange(postCo,-N)
```

```{r wordcloud}
# Using word cloud (thank you whitney) to compare positive words (the greatest number for both pre and post COVID)
#word cloud of 50 most frequently used negative and positive words

# PRE
df_prePost %>% 
  filter(postCo==0) %>% 
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "green"),
                   max.words = 50)
# POST
df_prePost %>% 
  filter(postCo==1) %>% 
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "green"),
                   max.words = 50)
```


```{r}
sentiment_by_time <- df_long %>%
    #mutate(date2 = floor_date(show_date, unit = "6 months")) %>%
    group_by(date) %>%
    mutate(total_words = n()) %>%
    ungroup() %>%
    inner_join(get_sentiments("nrc"))

library(ggplot2) # for some reason this is required again.
sentiment_by_time %>%
    filter(sentiment %in% c("positive", "negative")) %>%
    count(date, sentiment, total_words) %>%
    ungroup() %>%
    mutate(percent = n / total_words) %>%
    ggplot(aes(date, percent, color = sentiment)) +
    geom_line(size = 1.5) +
    geom_smooth(method = "lm", se = FALSE, lty = 2) +
    expand_limits(y = 0)

sentiment_by_time %>%
    filter(sentiment %in% c("anger", "sadness")) %>%
    count(date, sentiment, total_words) %>%
    ungroup() %>%
    mutate(percent = n / total_words) %>%
    ggplot(aes(date, percent, color = sentiment)) +
    geom_line(size = 1.5) +
    geom_smooth(method = "lm", se = FALSE, lty = 2) +
    expand_limits(y = 0)

df_filterNRCwords %>% filter(sentiment=="anger") %>% group_by(word) %>% summarize(N=n()) %>% arrange(-N)

# HOW INDIVIDUAL WORDS HAVE BEEN USED OVER TIME
df_long %>% 
    # mutate(date2 = floor_date(show_date, unit = "1 month")) %>%
    filter(word %in% c("challenge", "bias", "violence",
                       "advocacy", "hate", "disease")) %>%
    count(date, word) %>%
    ungroup() %>%
    ggplot(aes(date, n, color = word)) +
    # Make facets by word
    facet_wrap(~word) +
    geom_line(size = 1.5, show.legend = FALSE) +
    expand_limits(y = 0)
```


